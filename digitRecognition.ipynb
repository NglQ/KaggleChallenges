{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digitRecognition.ipynb",
      "provenance": [],
      "mount_file_id": "15XjwhVkwXGKHPzpAb6-8tIlQ8-c0EKb8",
      "authorship_tag": "ABX9TyOb9HKsqpByW2EPSADZLNyg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NglQ/KaggleChallenges/blob/main/digitRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rf8QqD9eWET-"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "D7SftXUMN-23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "ydNLRpTsUiHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c digit-recognizer"
      ],
      "metadata": {
        "id": "wOO8oQe0VEQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip digit-recognizer.zip\n",
        "!rm digit-recognizer.zip"
      ],
      "metadata": {
        "id": "IOkjlChQXrfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.mkdir('./train')\n",
        "os.mkdir('./test')\n",
        "\n",
        "for i in range(10):\n",
        "  os.mkdir(f'./train/{i}')"
      ],
      "metadata": {
        "id": "1_cs9Yjd7TbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "dataset = pd.read_csv('train.csv')\n",
        "trainset = dataset.copy().drop(columns='label')\n",
        "labels = dataset.copy()['label']\n",
        "\n",
        "testset = pd.read_csv('test.csv')\n",
        "\n",
        "means = trainset.mean()\n",
        "\n",
        "for i,row in trainset.iterrows():\n",
        "  rowNpArray = np.floor(np.array(row, dtype=np.uint8) - means)\n",
        "  imageOut = Image.new('L',(28,28))\n",
        "  imageOut.putdata(rowNpArray)\n",
        "  resizedImageOut = Image.new('L', (32, 32))\n",
        "  resizedImageOut.paste(imageOut, (2,2))\n",
        "  resizedImageOut.save(f'/content/train/{labels[i]}/image_{i}.png')\n",
        "\n",
        "for i,row in testset.iterrows():\n",
        "  rowNpArray = np.floor(np.array(row, dtype=np.uint8) - means)\n",
        "  imageOut = Image.new('L',(28,28))\n",
        "  imageOut.putdata(rowNpArray)\n",
        "  resizedImageOut = Image.new('L', (32, 32))\n",
        "  resizedImageOut.paste(imageOut, (2,2))\n",
        "  resizedImageOut.save(f'/content/test/image_{i}.png')\n",
        "  print(i)\n"
      ],
      "metadata": {
        "id": "PT_b0o13c3w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf \n",
        "import tensorflow.keras.preprocessing as tf_preproc\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import InceptionResNetV2, EfficientNetB0, VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import datetime, os\n",
        "\n",
        "train_dir = '/content/train'\n",
        "\n",
        "trainGenerator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    zoom_range = 0.05,\n",
        "    fill_mode = \"nearest\",\n",
        "    validation_split = 0.2)\n",
        "\n",
        "train_ds = trainGenerator.flow_from_directory(train_dir, target_size=(32,32), batch_size=70, subset='training')\n",
        "print(type(train_ds))\n",
        "val_ds = trainGenerator.flow_from_directory(train_dir, target_size=(32,32), batch_size=70, subset='validation')\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "inc = VGG16(input_shape =(32,32,3), include_top = False)\n",
        "\n",
        "model.add(inc)\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(10,activation = \"softmax\"))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "cBack = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=25, mode='max', restore_best_weights=True)\n",
        "checkPointCb = tf.keras.callbacks.ModelCheckpoint(filepath=\"/content/drive/MyDrive/models/digitRecognizer.h5\", monitor='val_accuracy', save_best_only=True)\n",
        "\n",
        "model.fit(train_ds, epochs = 100, callbacks=[tensorboard_callback,cBack,checkPointCb], validation_data = val_ds)\n"
      ],
      "metadata": {
        "id": "Cq1YcsGyojAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "model = keras.models.load_model('/content/drive/MyDrive/models/digitRecognizer.h5')\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "imgAcc = []\n",
        "idxs = []\n",
        "for root, dirs, files in os.walk('/content/test'):\n",
        "  for f in files:\n",
        "    img = tf.keras.preprocessing.image.load_img(f'{root}/{f}')\n",
        "    imgArr = image.img_to_array(img) #- means\n",
        "    # print(\"len img arr: \", len(imgArr))\n",
        "    imgArr = np.expand_dims(imgArr, axis = 0)\n",
        "    imgAcc.append(np.array(imgArr))\n",
        "    print(f.split('_')[1].split('.')[0])\n",
        "    idxs.append(int(f.split('_')[1].split('.')[0])+1)\n",
        "\n",
        "print(max(idxs), len(imgAcc))\n",
        "\n",
        "imgsToPredict = np.vstack(imgAcc)\n",
        "results = model.predict(imgsToPredict)\n",
        "\n",
        "idxsRes = []\n",
        "for res in results:\n",
        "  k = [i for i,val in enumerate(res) if val == 1.0]\n",
        "  if len(k) != 0:\n",
        "    idxsRes.append(k[0])\n",
        "  else:\n",
        "    idxsRes.append(0)\n",
        "\n",
        "filepath = Path('outDigitRecognizer.csv') \n",
        "outDf = pd.DataFrame({'ImageId': idxs, 'Label': idxsRes})\n",
        "outDf.to_csv(filepath, index = False, header=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "IeNh2F-dP_r_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "vNFTnttdUHBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "FSWCCpB0HzBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r train test"
      ],
      "metadata": {
        "id": "gNSYwp7Tlv-w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}