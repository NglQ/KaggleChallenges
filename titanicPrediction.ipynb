{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "titanicPrediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+6WVw/+r3ZzVKmfaG/VGR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NglQ/KaggleChallenges/blob/main/titanicPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OoLA8K5rNTAV"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "D7SftXUMN-23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "ydNLRpTsUiHa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c titanic"
      ],
      "metadata": {
        "id": "wOO8oQe0VEQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install skfeature-chappers"
      ],
      "metadata": {
        "id": "okRth5GWYGbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import feature_selection\n",
        "from numpy.core.numeric import NaN\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn as skl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_selection import SelectKBest, chi2, RFE, SelectFromModel, mutual_info_classif\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "pd.set_option('max_columns', None)\n",
        "\n",
        "def importDataset(stringPath):\n",
        "  return pd.read_csv(stringPath)\n",
        "\n",
        "def splitTrainVal(dataset):\n",
        "  datasetTrain, datasetVal = train_test_split(dataset, test_size=0.2)\n",
        "  return datasetTrain, datasetVal\n",
        "\n",
        "def splitDataset(datasetTrain):\n",
        "  features = datasetTrain.copy().drop(columns=['Survived','Ticket','PassengerId', 'Cabin'])\n",
        "  target = datasetTrain.copy()['Survived']    \n",
        "  return features, target\n",
        "\n",
        "\n",
        "def featureEngineering(featuresE):\n",
        "  Title_Dictionary = {\n",
        "    \"Capt\": \"Officer\",\n",
        "    \"Col\": \"Officer\",\n",
        "    \"Major\": \"Officer\",\n",
        "    \"Jonkheer\": \"Royalty\",\n",
        "    \"Don\": \"Royalty\",\n",
        "    \"Sir\" : \"Royalty\",\n",
        "    \"Dr\": \"Officer\",\n",
        "    \"Rev\": \"Officer\",\n",
        "    \"the Countess\":\"Royalty\",\n",
        "    \"Mme\": \"Mrs\",\n",
        "    \"Mlle\": \"Miss\",\n",
        "    \"Ms\": \"Mrs\",\n",
        "    \"Mr\" : \"Mr\",\n",
        "    \"Mrs\" : \"Mrs\",\n",
        "    \"Miss\" : \"Miss\",\n",
        "    \"Master\" : \"Master\",\n",
        "    \"Lady\" : \"Royalty\"\n",
        "  }\n",
        "\n",
        "  featuresE['Title'] = featuresE['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
        "  featuresE['Title'] = featuresE.Title.map(Title_Dictionary)\n",
        "\n",
        "  titles = pd.get_dummies(featuresE[\"Title\"], prefix='Title')\n",
        "\n",
        "  s = pd.get_dummies(featuresE[\"Sex\"], prefix='Sex')\n",
        "  pclass = pd.get_dummies(featuresE[\"Pclass\"], prefix='Pclass')\n",
        "  e = pd.get_dummies(featuresE[\"Embarked\"], prefix='Embarked')\n",
        "\n",
        "  featuresE['Family'] = featuresE['SibSp'] + featuresE['Parch']\n",
        "  featuresE['Fare_Person'] = featuresE['Fare'] / (featuresE['Family'] + 1)\n",
        "\n",
        "  featuresE = featuresE.drop(columns=['Sex','Pclass','Embarked', 'SibSp', 'Parch', 'Fare','Name'])\n",
        "  # features = features.drop(columns=['Sex','Pclass','Embarked', 'SibSp', 'Parch'])\n",
        "  # features = features.drop(columns=['Sex','Pclass','Embarked'])\n",
        "  featuresE = featuresE.join(s)\n",
        "  featuresE = featuresE.join(pclass)\n",
        "  featuresE = featuresE.join(e)\n",
        "  featuresE = featuresE.join(titles)\n",
        "  featuresE = featuresE.drop(columns = 'Title')\n",
        "  featuresE = featuresE.drop(columns= 'Sex_male')\n",
        "\n",
        "  y = featuresE.copy().loc[featuresE['Age'].isna()]\n",
        "  y = y.drop(columns='Age')\n",
        "  newDataset = featuresE.copy()\n",
        "  newDataset['Fare_Person'] = newDataset['Fare_Person'].fillna(featuresE.median(skipna = True)['Fare_Person'])\n",
        "  newDataset = newDataset.dropna() \n",
        "\n",
        "  newTarget = newDataset['Age']\n",
        "  newFeatures = newDataset.drop(columns = 'Age')\n",
        "  neigh = KNeighborsRegressor(n_neighbors=3)\n",
        "  neigh.fit(newFeatures, newTarget)\n",
        "  outY = neigh.predict(y)\n",
        "  y['Age'] = outY\n",
        "  featuresE = newDataset.append(y, ignore_index = True)\n",
        "  \n",
        "  return featuresE\n",
        "\n",
        "def computeScores(features, target):\n",
        "  print(features.describe(include = \"all\"))\n",
        "\n",
        "  print(\"correlation:\")\n",
        "  print(features.corr())\n",
        "  plt.matshow(features.corr())\n",
        "  plt.show()\n",
        "\n",
        "  print(\"correlation with 'survived': \")\n",
        "  corrDict = {key: abs(value) for key, value in zip(features.columns, features.corrwith(target))}\n",
        "  print(dict(sorted(corrDict.items(), key=lambda item: item[1], reverse=True)))\n",
        "\n",
        "  print(\"mutual information:\")\n",
        "  mic = mutual_info_classif(features, target, discrete_features=True)\n",
        "  dicMic = {key: value for key, value in zip(features.columns, mic)}\n",
        "  print(dict(sorted(dicMic.items(), key=lambda item: item[1], reverse=True)))\n",
        "\n",
        "  print(\"Linear regression score: \")\n",
        "  lr = LinearRegression()\n",
        "  rfe = RFE(estimator=lr, n_features_to_select=1, step=1)\n",
        "  rfe.fit(features, target)\n",
        "  rfeDict = {key: value for key, value in zip(features.columns, rfe.ranking_)}\n",
        "  print(dict(sorted(rfeDict.items(), key=lambda item: item[1], reverse=True)))\n",
        "\n",
        "  print(\"SVM score: \")\n",
        "  svc = SVC(kernel=\"linear\", C=1)\n",
        "  rfeSvc = RFE(estimator=svc, n_features_to_select=1, step=1)\n",
        "  rfeSvc.fit(features, target)\n",
        "  rfeSvcDict = {key: value for key, value in zip(features.columns, rfeSvc.ranking_)}\n",
        "  print(dict(sorted(rfeSvcDict.items(), key=lambda item: item[1], reverse=True)))\n",
        "\n",
        "  print(\"chi^2 score: \")\n",
        "  X_new_withfitTransform = SelectKBest(chi2, k=len(features.columns)).fit(features, target)\n",
        "  col = X_new_withfitTransform.get_feature_names_out(features.columns)\n",
        "  print(col)\n",
        "\n",
        "  print(\"Tree score: \")\n",
        "  clf = ExtraTreesClassifier(n_estimators=len(features.columns))\n",
        "  clf = clf.fit(features, target)\n",
        "  clfDict = {key: value for key, value in zip(features.columns, clf.feature_importances_)}\n",
        "  print(dict(sorted(clfDict.items(), key=lambda item: item[1], reverse=True)))\n",
        "\n",
        "def trainModel(features, target):\n",
        "  clf = RandomForestClassifier(max_depth=3, random_state=0)\n",
        "  clf.fit(features, target)\n",
        "  return clf\n",
        "\n",
        "def makePredictions(model, testSetFeatures):\n",
        "  return model.predict(testSetFeatures)\n",
        "\n",
        "def writeCsv(idx, predictions):\n",
        "  filepath = Path('outTitanic.csv') \n",
        "  outDf = pd.DataFrame({'PassengerId':idx, 'Survived':predictions})\n",
        "  outDf.to_csv(filepath, index = False, header=True)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  dataset = importDataset('train.csv')\n",
        "  dataset_test = importDataset('test.csv')\n",
        "  features, target = splitDataset(dataset)\n",
        "  features = featureEngineering(features)\n",
        "  computeScores(features, target)\n",
        "  features_test = dataset_test.copy().drop(columns=['Ticket','PassengerId', 'Cabin'])\n",
        "  features_test = featureEngineering(features_test)\n",
        "  features_test['Title_Royalty'] = np.zeros(len(features_test))\n",
        "  model = trainModel(features, target)\n",
        "  predictions = makePredictions(model, features_test)\n",
        "  writeCsv(dataset_test['PassengerId'], predictions)\n"
      ],
      "metadata": {
        "id": "Z5t5tujpVYt7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}